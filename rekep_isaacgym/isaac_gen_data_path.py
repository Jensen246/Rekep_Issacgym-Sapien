"""
IsaacGymç‰ˆæœ¬çš„æ•°æ®ç”Ÿæˆå’Œè·¯å¾„æ‰§è¡Œè„šæœ¬
è¿ç§»è‡ªReKepWithSapien/sapien_gen_data_path.py
ğŸ‘‰ å·²ä¸ºæ‰€æœ‰ actor è®¾ç½® segmentationIdï¼Œç¡®ä¿è¯­ä¹‰åˆ†å‰²ä¸å†å…¨ 0
"""
import numpy as np
import os
import yaml
import imageio
import math
import time
import json
import matplotlib.pyplot as plt
from scipy import interpolate

from isaacgym import gymapi, gymtorch, gymutil
import torch
from transform_utils import euler2quat, convert_quat
from utils import get_config
from ik_solver import IKSolver  # å¯¼å…¥IKæ±‚è§£å™¨

from utils import get_config
import environment


class IsaacGymDataGenerator:
    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶
        self.urdf_path = get_config(config_path='./configs/config.yaml')['urdf_path']
        self.srdf_path = get_config(config_path='./configs/config.yaml')['srdf_path']

        # ========== åŸºæœ¬åˆå§‹åŒ– ==========
        self.gym = gymapi.acquire_gym()
        self.sim_params = gymapi.SimParams()
        self.sim_params.substeps = 1
        self.sim_params.dt = 1.0 / 60.0
        self.sim_params.physx.solver_type = 1
        self.sim_params.physx.num_position_iterations = 6
        self.sim_params.physx.num_velocity_iterations = 0
        self.sim_params.physx.contact_offset = 0.01
        self.sim_params.physx.rest_offset = 0.0
        self.sim_params.up_axis = gymapi.UP_AXIS_Z
        self.sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.8)

        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, self.sim_params)
        if self.sim is None:
            print("Failed to create simulation")
            quit()

        self.create_ground()
        self.camera_data_path = './data/sensor'
        os.makedirs(self.camera_data_path, exist_ok=True)

        self.load_robot()      # æœºå™¨äºº segId = 1
        self.add_box()         # box1 segId = 101, box2 segId = 102

        self.create_viewer()
        self.create_camera_sensor()

        # æ‰§è¡Œä¸€æ¬¡æ¨¡æ‹Ÿä»¥å®Œæˆåˆå§‹åŒ–
        self.gym.simulate(self.sim)
        self.gym.fetch_results(self.sim, True)
        self.get_robot_state()
        
        # åˆå§‹åŒ–è§†å›¾å™¨
        self.viewer_created = True
        
        # åˆå§‹åŒ–IKæ±‚è§£å™¨
        global_config = get_config(config_path='./configs/config.yaml')
        self.env = environment.ReKepRealEnv(global_config['env'])        
        self.ik_solver = IKSolver(reset_joint_pos=self.env.reset_joint_pos,
                                  world2robot_homo=self.env.world2robot_homo)

    # --------------------------------------------------------------------------
    #
    # åŸºç¡€ç¯å¢ƒ
    # --------------------------------------------------------------------------
    #
    def create_ground(self):
        plane_params = gymapi.PlaneParams()
        plane_params.normal = gymapi.Vec3(0, 0, 1)
        self.gym.add_ground(self.sim, plane_params)

    # --------------------------------------------------------------------------
    #
    # æœºå™¨äºº & ç‰©ä½“
    # --------------------------------------------------------------------------
    #
    def load_robot(self):
        self.env_spacing = 1.5
        self.num_envs = 1
        self.envs = []

        pose = gymapi.Transform()
        pose.p = gymapi.Vec3(0.0, 0.0, 0.0)

        asset_root = "./data"
        asset_file = "franka_description/robots/franka_panda.urdf"
        self.urdf_full_path = os.path.join(asset_root, asset_file)
        
        asset_options = gymapi.AssetOptions()
        asset_options.fix_base_link = True
        asset_options.armature = 0.01
        asset_options.disable_gravity = True
        asset_options.flip_visual_attachments = True

        print(f"åŠ è½½æœºå™¨äººï¼š{self.urdf_full_path}")
        self.robot_asset = self.gym.load_asset(self.sim, asset_root, asset_file, asset_options)
        
        
        self.env_lower = gymapi.Vec3(-self.env_spacing, -self.env_spacing, 0.0)
        self.env_upper = gymapi.Vec3(self.env_spacing, self.env_spacing, self.env_spacing)

        for i in range(self.num_envs):
            env = self.gym.create_env(self.sim, self.env_lower, self.env_upper, 1)
            self.envs.append(env)

            # segmentationId=0, å¿½ç•¥æœºå™¨äºº
            self.robot_handle = self.gym.create_actor(
                env, self.robot_asset, pose, "robot", i, 0, segmentationId=0)

            props = self.gym.get_actor_dof_properties(env, self.robot_handle)
            props["driveMode"].fill(gymapi.DOF_MODE_POS)
            props["stiffness"].fill(700.0)
            props["damping"].fill(200.0)
            self.gym.set_actor_dof_properties(env, self.robot_handle, props)
            self.num_dofs = self.gym.get_asset_dof_count(self.robot_asset)
            frank_dof_props = self.gym.get_asset_dof_properties(self.robot_asset)
            self.franka_lower_limits = frank_dof_props["lower"]
            self.franka_upper_limits = frank_dof_props["upper"]
            franka_mids = 0.3 * (self.franka_upper_limits + self.franka_lower_limits)
            self.default_dof_pos = np.zeros(self.num_dofs, dtype=np.float32)
            self.default_dof_pos[:7] = franka_mids[:7]
            self.default_dof_pos[7:] = self.franka_upper_limits[7:]
            self.dof_names = [self.gym.get_asset_dof_name(self.robot_asset, j) for j in range(self.num_dofs)]
            self.finger_joints_indices = [j for j, n in enumerate(self.dof_names)
                                          if n in ('panda_finger_joint1', 'panda_finger_joint2')]
            # è·å–å·¦æŒ‡å°–çš„åˆšä½“å½¢çŠ¶å±æ€§
            left_finger_shape_props = self.gym.get_actor_rigid_shape_properties(env, self.robot_handle)
            # è·å–å³æŒ‡å°–çš„åˆšä½“å½¢çŠ¶å±æ€§
            right_finger_shape_props = self.gym.get_actor_rigid_shape_properties(env, self.robot_handle)
            # è®¾ç½®å·¦æŒ‡å°–çš„æ‘©æ“¦ç³»æ•°
            for prop in left_finger_shape_props:
                prop.friction = 6.0  # è®¾ç½®ä¸ºè¾ƒé«˜çš„æ‘©æ“¦ç³»æ•°
            self.gym.set_actor_rigid_shape_properties(self.envs[0], self.robot_handle, left_finger_shape_props)

            # è®¾ç½®å³æŒ‡å°–çš„æ‘©æ“¦ç³»æ•°
            for prop in right_finger_shape_props:
                prop.friction = 6.0  # è®¾ç½®ä¸ºè¾ƒé«˜çš„æ‘©æ“¦ç³»æ•°
            self.gym.set_actor_rigid_shape_properties(self.envs[0], self.robot_handle, right_finger_shape_props)

        # è®¾ç½®åˆå§‹å…³èŠ‚ä½ç½®
        self.gym.set_actor_dof_position_targets(
            self.envs[0], self.robot_handle, self.default_dof_pos)
        
        for _ in range(100):
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)

    def add_box(self):
        box_size_small = 0.02
        box_size_large = 0.10
        box_asset_options = gymapi.AssetOptions()
        box_asset_options.density = 100

        box_asset_small = self.gym.create_box(self.sim, 6*box_size_small,
                                              box_size_small, box_size_small, box_asset_options)
        box_asset_large = self.gym.create_box(self.sim, box_size_large,
                                              box_size_large, box_size_large, box_asset_options)

        box1_pose = gymapi.Transform()
        box1_pose.p = gymapi.Vec3(0.3, -0.3, box_size_small / 2 + 0.001)
        # ä½¿ç”¨ç›´æ¥çš„å››å…ƒæ•°å€¼è®¾ç½®æ—‹è½¬45åº¦ï¼ˆç»•Zè½´ï¼‰
        # å››å…ƒæ•°æ ¼å¼[x,y,z,w]ï¼Œç»•Zè½´æ—‹è½¬45åº¦ = [0, 0, sin(45Â°/2), cos(45Â°/2)]
        box1_pose.r = gymapi.Quat(0.0, 0.0, 0.3826834, 0.9238795)

        box2_pose = gymapi.Transform()
        box2_pose.p = gymapi.Vec3(0.3, 0.3, box_size_large / 2 + 0.001)

        # boxes segmentationId=101 / 102
        self.box1_handle = self.gym.create_actor(
            self.envs[0], box_asset_small, box1_pose, "box1", 0, 0, segmentationId=101)
        self.box2_handle = self.gym.create_actor(
            self.envs[0], box_asset_large, box2_pose, "box2", 0, 0, segmentationId=102)

        self.gym.set_rigid_body_color(self.envs[0], self.box1_handle, 0,
                                      gymapi.MESH_VISUAL_AND_COLLISION, gymapi.Vec3(1, 0, 0))
        self.gym.set_rigid_body_color(self.envs[0], self.box2_handle, 0,
                                      gymapi.MESH_VISUAL_AND_COLLISION, gymapi.Vec3(0, 1, 0))
        
        # è·å– box1 çš„å½¢çŠ¶å±æ€§
        box1_shape_props = self.gym.get_actor_rigid_shape_properties(self.envs[0], self.box1_handle)
        for prop in box1_shape_props:
            prop.friction = 5  # è®¾ç½®æ‘©æ“¦ç³»æ•°
        self.gym.set_actor_rigid_shape_properties(self.envs[0], self.box1_handle, box1_shape_props)

        # è·å– box2 çš„å½¢çŠ¶å±æ€§
        box2_shape_props = self.gym.get_actor_rigid_shape_properties(self.envs[0], self.box2_handle)
        for prop in box2_shape_props:
            prop.friction = 5  # è®¾ç½®æ‘©æ“¦ç³»æ•°
        self.gym.set_actor_rigid_shape_properties(self.envs[0], self.box2_handle, box2_shape_props)

    # --------------------------------------------------------------------------
    #
    # Viewer & Camera
    # --------------------------------------------------------------------------
    #
    def create_viewer(self):
        self.camera_props = gymapi.CameraProperties()
        self.camera_props.width = 640
        self.camera_props.height = 480
        self.viewer = self.gym.create_viewer(self.sim, self.camera_props)
        if self.viewer is None:
            print("æ— æ³•åˆ›å»ºè§†å›¾å™¨")
            quit()

        cam_pos = gymapi.Vec3(0.9, 0.0, 0.9)
        cam_target = gymapi.Vec3(0.0, 0.0, 0.0)
        self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)

        self.gym.subscribe_viewer_keyboard_event(self.viewer, gymapi.KEY_ESCAPE, "QUIT")
        self.gym.subscribe_viewer_keyboard_event(self.viewer, gymapi.KEY_SPACE, "PAUSE")

    def create_camera_sensor(self):
        self.camera_props = gymapi.CameraProperties()
        self.camera_props.width = 640
        self.camera_props.height = 480
        self.camera_props.enable_tensors = True
        self.camera_handle = self.gym.create_camera_sensor(self.envs[0], self.camera_props)

        self.cam_pos = gymapi.Vec3(0.35, 0.0, 0.5)
        self.cam_target = gymapi.Vec3(0.3, 0.0, 0.0)
        self.gym.set_camera_location(self.camera_handle, self.envs[0], self.cam_pos, self.cam_target)

    # --------------------------------------------------------------------------
    #
    # å…³èŠ‚&æ§åˆ¶
    # --------------------------------------------------------------------------
    #
    def get_robot_state(self):
        self.dof_states = self.gym.get_actor_dof_states(self.envs[0], self.robot_handle, gymapi.STATE_ALL)
        self.dof_positions = [self.dof_states[i]['pos'] for i in range(self.num_dofs)]
        self.hand_handle = self.gym.find_actor_rigid_body_handle(self.envs[0], self.robot_handle, "panda_hand")
        self.base_footprint = self.gym.find_actor_rigid_body_handle(self.envs[0], self.robot_handle, "panda_link0")
    # --------------------------------------------------------------------------
    #
    # ç›¸æœºæ•°æ®
    # --------------------------------------------------------------------------
    #
    def _calculate_intrinsics(self) -> np.ndarray:  # Shape=(3,3)
        horizontal_fov = self.camera_props.horizontal_fov * np.pi / 180
        vertical_fov = 2 * np.arctan(self.camera_props.height / self.camera_props.width * np.tan(horizontal_fov / 2))
        
        f_x = (self.camera_props.width / 2.0) / np.tan(horizontal_fov / 2.0)
        f_y = (self.camera_props.height / 2.0) / np.tan(vertical_fov / 2.0)

        K = np.array(
            [
                [f_x, 0.0, self.camera_props.width / 2.0],
                [0.0, f_y, self.camera_props.height / 2.0],
                [0.0, 0.0, 1.0]
            ],
            dtype=np.float32
        )

        return K

    def _calculate_extrinsics(self) -> np.ndarray:  # Shape=(3,4)
        # å°†gymapi.Vec3è½¬æ¢ä¸ºnumpyæ•°ç»„
        cam_pos_np = np.array([self.cam_pos.x, self.cam_pos.y, self.cam_pos.z])
        cam_target_np = np.array([self.cam_target.x, self.cam_target.y, self.cam_target.z])

        # IsaacGym camera coordinate system is x-forward, y-right, z-up
        x_axis = cam_target_np - cam_pos_np
        x_axis = x_axis / np.linalg.norm(x_axis)
        tmp_z_axis = np.array([0, 0, 1])
        y_axis = np.cross(tmp_z_axis, x_axis)
        y_axis = y_axis / np.linalg.norm(y_axis)
        z_axis = np.cross(x_axis, y_axis)
        z_axis = z_axis / np.linalg.norm(z_axis)

        # OpenCV camera coordinate system is x-right, y-down, z-forward
        x_axis_opencv = -y_axis
        y_axis_opencv = -z_axis
        z_axis_opencv = x_axis

        pos = cam_pos_np
        rot = np.stack([x_axis_opencv, y_axis_opencv, z_axis_opencv], axis=1)

        T_c2w = np.eye(4, dtype=np.float32)
        T_c2w[0:3, 0:3] = rot
        T_c2w[0:3, 3] = pos

        T_w2c = np.linalg.inv(T_c2w)[:3, :]
        return T_w2c

    def get_masked_point_cloud(
        self,
        depth: torch.Tensor,
        mask: torch.Tensor,
        cam_intrinsics: torch.Tensor,
        cam_extrinsics: torch.Tensor
    ) -> torch.Tensor:
        H, W = depth.shape
        device = depth.device

        y, x = torch.meshgrid(torch.arange(H, device=device), torch.arange(W, device=device), indexing='ij')
        
        valid = mask.bool()
        x_valid = x[valid].float()
        y_valid = y[valid].float()
        depth_valid = -depth[valid].float()

        fx = cam_intrinsics[0, 0]
        fy = cam_intrinsics[1, 1]
        cx = cam_intrinsics[0, 2]
        cy = cam_intrinsics[1, 2]

        # u = X/Z*fx + cx
        # v = Y/Z*fy + cy
        X = (x_valid - cx) * depth_valid / fx
        Y = (y_valid - cy) * depth_valid / fy
        Z = depth_valid
        pts_cam = torch.stack((X, Y, Z), dim=1)  

        cam_extrinsics_homo = torch.cat([cam_extrinsics, torch.zeros_like(cam_extrinsics[:1, :])], dim=0)
        cam_extrinsics_homo[3, 3] = 1
        cam_extrinsics_homo_inv = torch.inverse(cam_extrinsics_homo)
        R = cam_extrinsics_homo_inv[:3, :3]
        t = cam_extrinsics_homo_inv[:3, 3]
        pts_world = torch.matmul(pts_cam, R.T) + t

        return pts_world

    def _save_point_cloud(self, depth):
        depth = torch.from_numpy(depth)
        mask = torch.ones_like(depth)
        cam_intrinsics = torch.from_numpy(self._calculate_intrinsics())  # è½¬æ¢ä¸ºtensor
        cam_extrinsics = torch.from_numpy(self._calculate_extrinsics())  # è½¬æ¢ä¸ºtensor
        pts_world = self.get_masked_point_cloud(depth, mask, cam_intrinsics, cam_extrinsics)
        H, W = depth.shape
        np.save(os.path.join(self.camera_data_path, "points_world.npy"), pts_world.cpu().numpy().reshape(H, W, 3))

    def get_camera_data(self):
        os.makedirs(self.camera_data_path, exist_ok=True)

        self.gym.step_graphics(self.sim)
        self.gym.render_all_camera_sensors(self.sim)

        self.gym.start_access_image_tensors(self.sim)
        color_tensor = gymtorch.wrap_tensor(
            self.gym.get_camera_image_gpu_tensor(
                self.sim, self.envs[0], self.camera_handle, gymapi.IMAGE_COLOR))
        depth_tensor = gymtorch.wrap_tensor(
            self.gym.get_camera_image_gpu_tensor(
                self.sim, self.envs[0], self.camera_handle, gymapi.IMAGE_DEPTH))
        seg_tensor = gymtorch.wrap_tensor(
            self.gym.get_camera_image_gpu_tensor(
                self.sim, self.envs[0], self.camera_handle, gymapi.IMAGE_SEGMENTATION))
        self.gym.end_access_image_tensors(self.sim)

        H, W = self.camera_props.height, self.camera_props.width
        color = color_tensor.clone().cpu().numpy().reshape(H, W, 4)
        depth = depth_tensor.clone().cpu().numpy().reshape(H, W)
        seg = seg_tensor.clone().cpu().numpy().reshape(H, W)

        # æ‰“å°ç›¸æœºæ•°æ®ä¿¡æ¯
        print("\n--------- ç›¸æœºæ•°æ®ç»Ÿè®¡ ---------")
        print(f"å½©è‰²å›¾åƒå½¢çŠ¶: {color.shape}, ç±»å‹: {color.dtype}")
        print(f"æ·±åº¦å›¾å½¢çŠ¶: {depth.shape}, ç±»å‹: {depth.dtype}")
        print(f"æ·±åº¦å›¾æ•°å€¼èŒƒå›´: [{depth.min()}, {depth.max()}]")
        print(f"åˆ†å‰²å›¾å½¢çŠ¶: {seg.shape}, ç±»å‹: {seg.dtype}")
        print(f"åˆ†å‰²å›¾å”¯ä¸€å€¼: {np.unique(seg)}")
        print("--------------------------------\n")

        imageio.imwrite(os.path.join(self.camera_data_path, "color.png"), color[:, :, :3])
        depth_scaled = np.clip((-depth) * 1000, 0, 65535).astype(np.uint16)
        imageio.imwrite(os.path.join(self.camera_data_path, "depth.png"), depth_scaled)
        np.save(os.path.join(self.camera_data_path, "actor_mask.npy"), seg)
        
        # ç”Ÿæˆå¹¶ä¿å­˜ç‚¹äº‘
        self._save_point_cloud(depth)

        # è·å–å¹¶ä¿å­˜panda handçš„6Då§¿æ€
        hand_transform = self.gym.get_rigid_transform(self.envs[0], self.hand_handle)
        hand_pose = [
            float(hand_transform.p.x),
            float(hand_transform.p.y),
            float(hand_transform.p.z),
            float(hand_transform.r.x),
            float(hand_transform.r.y),
            float(hand_transform.r.z),
            float(hand_transform.r.w)
        ]
        
        base_footprint_transform = self.gym.get_rigid_transform(self.envs[0], self.base_footprint)
        base_footprint_pose = [
            float(base_footprint_transform.p.x),
            float(base_footprint_transform.p.y),
            float(base_footprint_transform.p.z),
            float(base_footprint_transform.r.x),
            float(base_footprint_transform.r.y),
            float(base_footprint_transform.r.z),
            float(base_footprint_transform.r.w)
        ]
        
        # å°†å§¿æ€ä¿å­˜ä¸ºJSONæ–‡ä»¶
        json_path = os.path.join(self.camera_data_path, "hand&base_pose.json")
        with open(json_path, 'w') as f:
            json.dump({
                "hand_pose": hand_pose,
                "base_footprint_pose": base_footprint_pose
            }, f, indent=4)

        print(f"Camera&robot_pose data saved to {self.camera_data_path}")

    # --------------------------------------------------------------------------
    #
    # ä¸»å¾ªç¯
    # --------------------------------------------------------------------------
    #
    def run(self):
        captured_camera_data = False
        frame_count = 0
        print("å¼€å§‹è¿è¡Œæ¨¡æ‹Ÿå¾ªç¯...")

        while not self.gym.query_viewer_has_closed(self.viewer):
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)

            self.dof_states = self.gym.get_actor_dof_states(self.envs[0], self.robot_handle, gymapi.STATE_ALL)
            self.dof_positions = [self.dof_states[i]['pos'] for i in range(self.num_dofs)]

            self.gym.step_graphics(self.sim)
            self.gym.draw_viewer(self.viewer, self.sim, False)
            self.gym.sync_frame_time(self.sim)

            frame_count += 1
            if not captured_camera_data and frame_count > 100:
                print("æ¨¡æ‹Ÿç¨³å®šï¼Œæ•è·ç›¸æœºæ•°æ®...")
                self.get_camera_data()
                captured_camera_data = True

            for evt in self.gym.query_viewer_action_events(self.viewer):
                if evt.action == "QUIT" and evt.value > 0:
                    return

        print("æŸ¥çœ‹å™¨å·²å…³é—­ï¼Œæ¸…ç†èµ„æº...")
        self.gym.destroy_viewer(self.viewer)
        self.gym.destroy_sim(self.sim)

    def exec_path(self, stage_result_list):
        """æ‰§è¡Œæ‰€æœ‰é˜¶æ®µçš„è·¯å¾„"""
        # åªæœ‰åœ¨æœªåˆ›å»ºè§†å›¾å™¨æ—¶æ‰åˆ›å»º
        if not self.viewer_created:
            self.create_viewer()
            self.viewer_created = True

        # æ‰§è¡Œæ¯ä¸ªé˜¶æ®µ
        for stage_result in stage_result_list:
            if stage_result['is_grasp_stage']:
                self.set_gripper(1.0)  # æ‰“å¼€å¤¹çˆª
                # åŠ¨æ€å§¿æ€å¯¹é½ï¼šä½¿ç”¨æŠ“å–å¯¹è±¡ box1ï¼ˆsegmentationId=101ï¼‰çš„å½“å‰å§¿æ€è°ƒæ•´æœ«ç«¯æ‰§è¡Œå™¨æœå‘
                box1_state = self.gym.get_actor_rigid_body_states(self.envs[0], self.box1_handle, gymapi.STATE_ALL)
                box2_state = self.gym.get_actor_rigid_body_states(self.envs[0], self.box2_handle, gymapi.STATE_ALL)
                # è·å– box1 å’Œ box2 çš„å¹³é¢ä½ç½® (x, y)
                px1 = float(box1_state["pose"]["p"]["x"][0]); py1 = float(box1_state["pose"]["p"]["y"][0])
                px2 = float(box2_state["pose"]["p"]["x"][0]); py2 = float(box2_state["pose"]["p"]["y"][0])
                # æ ¹æ®æœ«ç«¯è·¯å¾„æœ€åä¸€ç‚¹çš„ä½ç½®åˆ¤æ–­ç›®æ ‡å¯¹è±¡ï¼ˆbox1æˆ–box2ï¼‰
                target_x, target_y = stage_result['path'][-1][0], stage_result['path'][-1][1]
                dist1 = (target_x - px1)**2 + (target_y - py1)**2
                dist2 = (target_x - px2)**2 + (target_y - py2)**2
                if dist1 <= dist2:
                    # ç›®æ ‡ä¸º box1ï¼Œè·å– box1 å½“å‰å§¿æ€å››å…ƒæ•° (x, y, z, w)
                    bx = float(box1_state["pose"]["r"]["x"][0]); by = float(box1_state["pose"]["r"]["y"][0])
                    bz = float(box1_state["pose"]["r"]["z"][0]); bw = float(box1_state["pose"]["r"]["w"][0])
                else:
                    # ç›®æ ‡ä¸º box2ï¼Œè·å– box2 å½“å‰å§¿æ€å››å…ƒæ•°
                    bx = float(box2_state["pose"]["r"]["x"][0]); by = float(box2_state["pose"]["r"]["y"][0])
                    bz = float(box2_state["pose"]["r"]["z"][0]); bw = float(box2_state["pose"]["r"]["w"][0])
                # è®¡ç®—ç›®æ ‡æœ«ç«¯æ‰§è¡Œå™¨å››å…ƒæ•°ï¼šgoal_q = down_q * box_q_invï¼Œå…¶ä¸­ down_q = [1, 0, 0, 0]
                inv_bx, inv_by, inv_bz, inv_bw = -bx, -by, -bz, bw   # box_q çš„å…±è½­ï¼ˆé€†ï¼‰
                dx, dy, dz, dw = 1.0, 0.0, 0.0, 0.0                 # æœä¸‹å‚è€ƒå››å…ƒæ•° down_q
                goal_w = dw * inv_bw - (dx * inv_bx + dy * inv_by + dz * inv_bz)
                goal_x = dw * inv_bx + inv_bw * dx + (dy * inv_bz - dz * inv_by)
                goal_y = dw * inv_by + inv_bw * dy + (dz * inv_bx - dx * inv_bz)
                goal_z = dw * inv_bz + inv_bw * dz + (dx * inv_by - dy * inv_bx)
                # å½’ä¸€åŒ– goal_qï¼Œé¿å…æ•°å€¼è¯¯å·®
                norm = math.sqrt(goal_w**2 + goal_x**2 + goal_y**2 + goal_z**2)
                if norm > 1e-6:
                    goal_w, goal_x, goal_y, goal_z = goal_w/norm, goal_x/norm, goal_y/norm, goal_z/norm
                # æ›¿æ¢æŠ“å–é˜¶æ®µæœ«ç«¯è·¯å¾„ç‚¹çš„å§¿æ€ä¸ºè®¡ç®—å¾—åˆ°çš„ goal_q
                stage_result['path'][-1][3:7] = [goal_x, goal_y, goal_z, goal_w]
            else:
                self.set_gripper(0.0)  # å…³é—­å¤¹çˆª

            # æ‰§è¡Œè·¯å¾„
            self.plan_and_execute_path(
                stage_result['path'],
                is_grasp_stage=stage_result['is_grasp_stage'],
                is_release_stage=stage_result['is_release_stage']
            )

            if stage_result['is_release_stage']:
                self.set_gripper(1.0)  # æ‰“å¼€å¤¹çˆª
            else:
                if stage_result['is_grasp_stage']:
                    grasp_pose = stage_result['path'][-1] + np.array([0, 0, -0.02, 0, 0, 0, 0])
                    self.move_to_pose(grasp_pose, is_grasp_stage=True, is_release_stage=False)
                self.set_gripper(0.0)  # å…³é—­å¤¹çˆª

        print("æ‰€æœ‰é˜¶æ®µæ‰§è¡Œå®Œæˆ")

        # ä¿æŒçª—å£æ‰“å¼€ï¼Œç›´åˆ°ç”¨æˆ·å…³é—­
        while not self.gym.query_viewer_has_closed(self.viewer):
            # æ›´æ–°ç‰©ç†å’Œæ¸²æŸ“
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)
            self.gym.step_graphics(self.sim)
            self.gym.draw_viewer(self.viewer, self.sim, False)
            self.gym.sync_frame_time(self.sim)

            # æ£€æŸ¥é€€å‡ºäº‹ä»¶
            for evt in self.gym.query_viewer_action_events(self.viewer):
                if evt.action == "QUIT" and evt.value > 0:
                    return

    def plan_and_execute_path(self, end_effector_path, is_grasp_stage=False, is_release_stage=False):
        """æ‰§è¡Œç«¯ç‚¹è½¨è¿¹
        Args:
            end_effector_path: æœ«ç«¯æ‰§è¡Œå™¨è·¯å¾„ï¼Œæ¯ä¸ªç‚¹æ˜¯ä¸€ä¸ª[x,y,z,qx,qy,qz,qw]æ•°ç»„
            is_grasp_stage: æ˜¯å¦æ˜¯æŠ“å–é˜¶æ®µ
            is_release_stage: æ˜¯å¦æ˜¯é‡Šæ”¾é˜¶æ®µ
        """
        print(f"æ‰§è¡Œè·¯å¾„: {len(end_effector_path)}ä¸ªç‚¹")
        
        # éå†è·¯å¾„ä¸­çš„æ¯ä¸ªä½å§¿
        for i, pose in enumerate(end_effector_path):
            print(f"æ‰§è¡Œä½å§¿ {i+1}/{len(end_effector_path)}")
            self.move_to_pose(pose, is_grasp_stage, is_release_stage)
            
            # ç­‰å¾…æœºå™¨äººè¾¾åˆ°ä½ç½®
            # time.sleep(0.5)

    def move_to_pose(self, target_pose, is_grasp_stage, is_release_stage):
        """ä½¿ç”¨IKæ±‚è§£å™¨ç§»åŠ¨åˆ°æŒ‡å®šä½å§¿
        Args:
            target_pose: ç›®æ ‡ä½å§¿ï¼Œ[x,y,z,qx,qy,qz,qw]æ ¼å¼
        """
        # ä½¿ç”¨IKæ±‚è§£å™¨è®¡ç®—å…³èŠ‚è§’åº¦
        ik_result = self.ik_solver.solve(target_pose=target_pose, start_joint_pos=self.dof_positions[:7])

        if ik_result.success:
            # è·å–è®¡ç®—å‡ºçš„å…³èŠ‚è§’åº¦
            joint_positions = ik_result.cspace_position
            if is_grasp_stage:
                joint_positions = np.concatenate([joint_positions, [0.04, 0.04]]).astype(np.float32)
            elif is_release_stage:
                joint_positions = np.concatenate([joint_positions, [0.0, 0.0]]).astype(np.float32)
            # è®¾ç½®å…³èŠ‚ä½ç½®ç›®æ ‡
            self.gym.set_actor_dof_position_targets(
                self.envs[0], self.robot_handle, joint_positions)
            for _ in range(100):
                self.gym.simulate(self.sim)
                self.gym.fetch_results(self.sim, True)
                self.gym.step_graphics(self.sim)
                if self.viewer_created:
                    self.gym.draw_viewer(self.viewer, self.sim, False)
                    self.gym.sync_frame_time(self.sim)

        else:
            print(f"IKæ±‚è§£å¤±è´¥: {ik_result.status}")
        
        # è¿è¡Œæ¨¡æ‹Ÿä¸€æ®µæ—¶é—´ä»¥è®©æœºå™¨äººç§»åŠ¨åˆ°ç›®æ ‡
        steps = 100
        for _ in range(steps):
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)
            self.gym.step_graphics(self.sim)
            
            if self.viewer_created:
                self.gym.draw_viewer(self.viewer, self.sim, False)
                self.gym.sync_frame_time(self.sim)

        # æ›´æ–°æœºå™¨äººçŠ¶æ€
        self.get_robot_state()

        # è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿
        hand_transform = self.gym.get_rigid_transform(self.envs[0], self.hand_handle)

        # è®¡ç®—ä½ç½®è¯¯å·®
        pos_error = np.sqrt(
            (hand_transform.p.x - target_pose[0])**2 +
            (hand_transform.p.y - target_pose[1])**2 +
            (hand_transform.p.z - target_pose[2])**2
        )

        # è®¡ç®—å§¿æ€è¯¯å·®ï¼ˆå››å…ƒæ•°ï¼‰
        quat_error = np.sqrt(
            (hand_transform.r.x - target_pose[3])**2 +
            (hand_transform.r.y - target_pose[4])**2 +
            (hand_transform.r.z - target_pose[5])**2 +
            (hand_transform.r.w - target_pose[6])**2
        )

        # æ‰“å°ä½å§¿å¯¹æ¯”å’Œè¯¯å·®
        print("\n--------- ä½å§¿å¯¹æ¯” ---------")
        print(f"ç›®æ ‡ä½ç½®: [{target_pose[0]:.4f}, {target_pose[1]:.4f}, {target_pose[2]:.4f}]")
        print(f"å®é™…ä½ç½®: [{hand_transform.p.x:.4f}, {hand_transform.p.y:.4f}, {hand_transform.p.z:.4f}]")
        print(f"ä½ç½®è¯¯å·®: {pos_error:.4f}")
        print(f"ç›®æ ‡å§¿æ€: [{target_pose[3]:.4f}, {target_pose[4]:.4f}, {target_pose[5]:.4f}, {target_pose[6]:.4f}]")
        print(f"å®é™…å§¿æ€: [{hand_transform.r.x:.4f}, {hand_transform.r.y:.4f}, {hand_transform.r.z:.4f}, {hand_transform.r.w:.4f}]")
        print(f"å§¿æ€è¯¯å·®: {quat_error:.4f}")
        print("---------------------------\n")

    def set_gripper(self, position, steps=50):
        """è®¾ç½®å¤¹çˆªä½ç½®
        
        Args:
            position: ä½ç½®å€¼ï¼Œ0è¡¨ç¤ºé—­åˆï¼Œ1è¡¨ç¤ºæ‰“å¼€
            steps: æ‰§è¡Œæ­¥æ•°
        """
        current_positions = self.dof_positions[-2:]
        target_positions = [position, position]
        
        # åˆ›å»ºå®Œæ•´çš„å…³èŠ‚ä½ç½®æ•°ç»„
        full_targets = np.array(self.dof_positions)
        
        for i in range(steps):
            t = (i + 1) / steps
             
            # çº¿æ€§æ’å€¼
            interp_positions = [
                current_positions[j] * (1-t) + target_positions[j] * t
                for j in range(2)
            ]
            
            # æ›´æ–°å¤¹çˆªå…³èŠ‚ä½ç½®
            for j, idx in enumerate(self.finger_joints_indices):
                full_targets[idx] = interp_positions[j]
            
            # è®¾ç½®æ‰€æœ‰å…³èŠ‚ä½ç½®ç›®æ ‡
            self.gym.set_actor_dof_position_targets(self.envs[0], self.robot_handle, full_targets)
            
            # æ‰§è¡Œæ¨¡æ‹Ÿæ­¥éª¤
            self.gym.simulate(self.sim)
            self.gym.fetch_results(self.sim, True)
            self.gym.step_graphics(self.sim)
            
            # æ›´æ–°æ˜¾ç¤º
            if self.viewer_created:
                self.gym.draw_viewer(self.viewer, self.sim, False)
                self.gym.sync_frame_time(self.sim)
        
        # æ›´æ–°å½“å‰å¤¹çˆªä½ç½®
        self.get_robot_state()


if __name__ == "__main__":
    isaac_data_generator = IsaacGymDataGenerator()
    print("å¼€å§‹è¿è¡Œæ¨¡æ‹Ÿ...")
    isaac_data_generator.run()
    print("æ¨¡æ‹Ÿç»“æŸ")
